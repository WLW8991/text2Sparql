{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec106847-1215-40e1-8cb2-7d3b8d016f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T08:43:56.648466Z",
     "iopub.status.busy": "2022-11-04T08:43:56.645998Z",
     "iopub.status.idle": "2022-11-04T08:43:56.699756Z",
     "shell.execute_reply": "2022-11-04T08:43:56.698236Z",
     "shell.execute_reply.started": "2022-11-04T08:43:56.648349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f7056f-2c06-4712-b484-89e5db201891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T08:43:56.709740Z",
     "iopub.status.busy": "2022-11-04T08:43:56.708646Z",
     "iopub.status.idle": "2022-11-04T08:43:57.346825Z",
     "shell.execute_reply": "2022-11-04T08:43:57.344808Z",
     "shell.execute_reply.started": "2022-11-04T08:43:56.709697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_train = json.load(open('./preprocess/raw_train.json'))\n",
    "raw_test = json.load(open('./preprocess/raw_test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde466aa-f549-4f4e-a8f0-868969f36b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T08:43:57.366754Z",
     "iopub.status.busy": "2022-11-04T08:43:57.364134Z",
     "iopub.status.idle": "2022-11-04T08:43:57.469692Z",
     "shell.execute_reply": "2022-11-04T08:43:57.468648Z",
     "shell.execute_reply.started": "2022-11-04T08:43:57.366710Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocess(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        ent_labels = json.load(open('./preprocess/all_entity.json', 'rb'))\n",
    "        rel_labels = json.load(open('./preprocess/all_relation.json', 'rb'))\n",
    "        \n",
    "        vocab=['\"', '(', 'rdfs:label', 'by', 'ask', '>', 'select', 'que', 'limit', 'jai', 'mai', \n",
    "        '?sbj', ')', 'lang', 'year', '}', '?value', 'peint', 'desc', 'where', 'ce', 'distinct', \n",
    "       'filter', 'lcase', 'order', 'la', '<', 'asc', 'en', 'contains', 'as', ',', 'strstarts', \n",
    "       '{', \"'\", 'j', 'count', '=', '.', '?vr0', '?vr1', '?vr2', '?vr3', '?vr4', '?vr5', '?vr6', \n",
    "       '?vr0_label', '?vr1_label', '?vr2_label', '?vr3_label', '?vr4_label', '?vr5_label', '?vr6_label',\n",
    "       'wd:', 'wdt:', 'ps:', 'p:', 'pq:', '?maskvar1', '[DEF]','null']\n",
    "\n",
    "        vocab_dict={}\n",
    "        for i,text in enumerate(vocab):\n",
    "            vocab_dict[text]='<extra_id_'+str(i)+'>'\n",
    "\n",
    "        for kk in ent_labels:\n",
    "            if ent_labels[kk] is None: ent_labels[kk] = vocab_dict['null']\n",
    "\n",
    "        self.ent_labels = ent_labels\n",
    "        self.rel_labels = rel_labels\n",
    "        self.vocab_dict = vocab_dict\n",
    "\n",
    "    \n",
    "    def _preprocess(self, data):\n",
    "        wikisparql = data['sparql_wikidata']\n",
    "        raw_question = data['question']\n",
    "        if raw_question is None:\n",
    "            raw_question = data['NNQT_question']\n",
    "        raw_question = raw_question.replace('}','').replace('{','')\n",
    "\n",
    "        sparql = wikisparql.replace('(',' ( ').replace(')',' ) ').replace('{',' { ')\\\n",
    "        .replace('}',' } ').replace(':',': ').replace(',',' , ').replace(\"'\",\" ' \")\\\n",
    "        .replace('.',' . ').replace('=',' = ').lower()\n",
    "        sparql = ' '.join(sparql.split())\n",
    "        \n",
    "        _ents = re.findall( r'wd: (?:.*?) ', sparql)\n",
    "        # _ents_for_labels = re.findall( r'wd: (.*?) ', sparql)\n",
    "        \n",
    "        _rels = re.findall( r'wdt: (?:.*?) ',sparql)\n",
    "        _rels += re.findall( r' p: (?:.*?) ',sparql)\n",
    "        _rels += re.findall( r' ps: (?:.*?) ',sparql)\n",
    "        _rels += re.findall( r'pq: (?:.*?) ',sparql)\n",
    "        \n",
    "        # _rels_for_labels = re.findall( r'wdt: (.*?) ',sparql)\n",
    "        # _rels_for_labels += re.findall( r' p: (.*?) ',sparql)\n",
    "        # _rels_for_labels += re.findall( r' ps: (.*?) ',sparql)\n",
    "        # _rels_for_labels += re.findall( r'pq: (.*?) ',sparql)\n",
    "\n",
    "#         for j in range(len(_ents_for_labels)):\n",
    "#             if '}' in _ents[j]: \n",
    "#                 _ents[j]=''\n",
    "#             _ents[j] = _ents[j] + self.ent_labels[_ents_for_labels[j]]+' '\n",
    "            \n",
    "#         for j in range(len(_rels_for_labels)):\n",
    "#             if _rels_for_labels[j] not in self.rel_labels:\n",
    "#                 self.rel_labels[_rels_for_labels[j]] = self.vocab_dict['null']\n",
    "#             _rels[j] = _rels[j] + self.rel_labels[_rels_for_labels[j]]+' '\n",
    "\n",
    "        # _ents += _rels\n",
    "    \n",
    "        newvars = ['?vr0','?vr1','?vr2','?vr3','?vr4','?vr5']\n",
    "        \n",
    "        variables = set([x for x in sparql.split() if x[0] == '?'])\n",
    "        for idx,var in enumerate(sorted(variables)):\n",
    "            if var == '?maskvar1':\n",
    "                continue         \n",
    "            sparql = sparql.replace(var,newvars[idx])\n",
    "            \n",
    "        split = sparql.split()\n",
    "        for idx, item in enumerate(split):\n",
    "            if item in self.ent_labels:\n",
    "                split[idx] = self.ent_labels[item]\n",
    "            elif item in self.rel_labels:\n",
    "                split[idx] = self.rel_labels[item]\n",
    "\n",
    "            if item in self.vocab_dict:\n",
    "                split[idx] = self.vocab_dict[item]\n",
    "        \n",
    "        gold_query = ' '.join(split).strip()\n",
    "        \n",
    "        question = raw_question\n",
    "        tail = ''\n",
    "        \n",
    "        for ent in _ents:\n",
    "            ent = ent.replace('wd:',self.vocab_dict['wd:']+' ')\n",
    "\n",
    "            ent_split = ent.split()\n",
    "            # index = 2 if bool(re.match('[pq][0-9]+', ent_split[1])) else 1\n",
    "            tail = tail+' '+self.vocab_dict['[DEF]']+' '+ ' '.join(ent_split)\n",
    "\n",
    "        for rel in _rels:\n",
    "            rel=rel.replace('wdt:', self.vocab_dict['wdt:']+' ')\n",
    "            rel=rel.replace('p:', self.vocab_dict['p:']+' ')\n",
    "            rel=rel.replace('ps:', self.vocab_dict['ps:']+' ')\n",
    "            rel=rel.replace('pq:', self.vocab_dict['pq:']+' ')\n",
    "\n",
    "            rel_split = rel.split()\n",
    "            # index = 2 if bool(re.match('[pq][0-9]+', rel_split[1])) else 1\n",
    "            tail = tail+' '+self.vocab_dict['[DEF]']+' '+' '.join(rel_split)\n",
    "        \n",
    "        tail_split = tail.split()\n",
    "        for idx, item in enumerate(tail_split):\n",
    "            if item in self.ent_labels:\n",
    "                tail_split[idx] = self.ent_labels[item]\n",
    "            elif item in self.rel_labels:\n",
    "                tail_split[idx] = self.rel_labels[item]\n",
    "                \n",
    "            \n",
    "        schema = ' '.join(tail_split).strip()\n",
    "        question_input = ' '.join(question.split()).strip()+' '+self.vocab_dict['[DEF]']+ ' ' +schema\n",
    "        \n",
    "        res = {\n",
    "                'input': question_input,    \n",
    "                'target': gold_query,\n",
    "               }\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044bad0b-b80d-4b08-903b-238cf8ef7d14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T08:43:57.477829Z",
     "iopub.status.busy": "2022-11-04T08:43:57.477538Z",
     "iopub.status.idle": "2022-11-04T08:43:57.686868Z",
     "shell.execute_reply": "2022-11-04T08:43:57.686040Z",
     "shell.execute_reply.started": "2022-11-04T08:43:57.477788Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54877654-7f10-4c49-aef5-00aa9d3f4568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-04T08:43:57.699704Z",
     "iopub.status.busy": "2022-11-04T08:43:57.697595Z",
     "iopub.status.idle": "2022-11-04T08:44:04.116238Z",
     "shell.execute_reply": "2022-11-04T08:44:04.115167Z",
     "shell.execute_reply.started": "2022-11-04T08:43:57.699661Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24180/24180 [00:03<00:00, 6328.23it/s]\n",
      "100%|██████████| 6046/6046 [00:01<00:00, 5553.86it/s]\n"
     ]
    }
   ],
   "source": [
    "train = [pre._preprocess(item) for item in tqdm(raw_train)]\n",
    "with open('train.json','w+') as file:\n",
    "    file.write(json.dumps(train, indent=2))\n",
    "    \n",
    "test = [pre._preprocess(item) for item in tqdm(raw_test)]\n",
    "with open('test.json','w+') as file:\n",
    "    file.write(json.dumps(test, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37] *",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
